# RLM Configuration
# Copy this file to .env and fill in your values

# ===================
# API Configuration
# ===================

# LLM Provider: openai, anthropic, or google
RLM_API_PROVIDER=openai

# Your API key for the selected provider
RLM_API_KEY=sk-your-api-key-here

# Model name to use
RLM_MODEL_NAME=gpt-4o

# ===================
# Execution Settings
# ===================

# Execution mode: docker (secure) or local (development only!)
RLM_EXECUTION_MODE=docker

# Docker runtime: auto (detect gVisor), runsc, or runc
RLM_DOCKER_RUNTIME=auto

# Docker image for sandbox
RLM_DOCKER_IMAGE=python:3.11-slim

# Execution timeout in seconds
RLM_EXECUTION_TIMEOUT=30

# ===================
# Safety Limits
# ===================

# Maximum cost limit in USD per session
RLM_COST_LIMIT_USD=5.0

# Maximum number of code execution iterations
RLM_MAX_RECURSION_DEPTH=5

# Maximum stdout bytes to capture
RLM_MAX_STDOUT_BYTES=4000

# ===================
# Security Settings
# ===================

# Container memory limit
RLM_MEMORY_LIMIT=512m

# CPU limit in cores
RLM_CPU_LIMIT=1.0

# Maximum number of processes in container
RLM_PIDS_LIMIT=50

# Enable network access (DANGEROUS - only for testing)
RLM_NETWORK_ENABLED=false

# ===================
# Egress Filtering
# ===================

# Shannon entropy threshold for secret detection
RLM_ENTROPY_THRESHOLD=4.5

# Minimum string length for entropy checking
RLM_MIN_ENTROPY_LENGTH=256

# Similarity threshold for context echo detection
RLM_SIMILARITY_THRESHOLD=0.8

# ===================
# Optional Paths
# ===================

# Path to custom pricing.json file
# RLM_PRICING_PATH=/path/to/pricing.json
